{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+cLZc57aSvYIf/9l+z+bK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prathibha-S/DataScience/blob/main/exp6_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YWR-yLMzFds9"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,Y_train),(X_valid,Y_valid) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma2Hq-5BFx6s",
        "outputId": "e007cf02-3cc2-4056-ac34-3baf2e8692ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train =X_train .reshape(60000,784).astype('float32')\n",
        "X_valid =X_valid .reshape(10000,784).astype('float32')"
      ],
      "metadata": {
        "id": "4l_zxQrtF0xT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train /=255\n",
        "X_valid /=255"
      ],
      "metadata": {
        "id": "mztC7KggGGVb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2CJzhwaGIQK",
        "outputId": "64599906-68c2-496d-b8da-eac0359d9ae8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
              "       0.5921569 , 0.23529412, 0.14117648, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.94509804, 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
              "       0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.6666667 ,\n",
              "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.2627451 , 0.44705883,\n",
              "       0.28235295, 0.44705883, 0.6392157 , 0.8901961 , 0.99607843,\n",
              "       0.88235295, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
              "       0.8980392 , 0.99607843, 0.99607843, 0.54901963, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
              "       0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
              "       0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.3254902 , 0.99215686, 0.81960785, 0.07058824,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.08627451, 0.9137255 ,\n",
              "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.5058824 , 0.99607843, 0.93333334, 0.17254902,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.23137255, 0.9764706 ,\n",
              "       0.99607843, 0.24313726, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.03529412, 0.8039216 ,\n",
              "       0.972549  , 0.22745098, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.49411765, 0.99607843, 0.7137255 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.29411766, 0.9843137 ,\n",
              "       0.9411765 , 0.22352941, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.07450981, 0.8666667 , 0.99607843, 0.6509804 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
              "       0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.14901961, 0.99607843, 0.99607843, 0.3019608 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.12156863, 0.8784314 , 0.99607843,\n",
              "       0.4509804 , 0.00392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.52156866, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.23921569, 0.9490196 , 0.99607843,\n",
              "       0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
              "       0.8117647 , 0.07058824, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import utils as np_utils\n",
        "n_classes=10\n",
        "Y_train=keras.utils.np_utils.to_categorical(Y_train,n_classes)\n",
        "Y_valid=keras.utils.np_utils.to_categorical(Y_valid,n_classes)"
      ],
      "metadata": {
        "id": "5g_yJT5UGKdi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_valid[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1p3Nz5eHBfp",
        "outputId": "e39405c0-e5de-4809-8fec-f5cb78010e1f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()"
      ],
      "metadata": {
        "id": "OSgp-WWvGKj7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(64,activation='sigmoid',input_shape=(784,)))"
      ],
      "metadata": {
        "id": "PuGovARDHG_A"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "z4LmmtRaHS6f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f19GAFUHaBn",
        "outputId": "a38263bb-63f6-4823-e80c-50b79794171b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mean_squared_error',optimizer=SGD(learning_rate=0.01),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "a5cEfzbFHchQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train,Y_train,batch_size=128,epochs=150,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "244hDXDlHf23",
        "outputId": "8dd5c184-02db-44c6-deac-573b233a3e39"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0912 - accuracy: 0.1264\n",
            "Epoch 2/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0908 - accuracy: 0.1467\n",
            "Epoch 3/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0903 - accuracy: 0.1650\n",
            "Epoch 4/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0900 - accuracy: 0.1812\n",
            "Epoch 5/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0896 - accuracy: 0.1992\n",
            "Epoch 6/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0892 - accuracy: 0.2192\n",
            "Epoch 7/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0889 - accuracy: 0.2378\n",
            "Epoch 8/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0885 - accuracy: 0.2573\n",
            "Epoch 9/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0882 - accuracy: 0.2709\n",
            "Epoch 10/150\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0878 - accuracy: 0.2826\n",
            "Epoch 11/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0875 - accuracy: 0.2915\n",
            "Epoch 12/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0872 - accuracy: 0.2993\n",
            "Epoch 13/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0868 - accuracy: 0.3057\n",
            "Epoch 14/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0865 - accuracy: 0.3095\n",
            "Epoch 15/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0861 - accuracy: 0.3153\n",
            "Epoch 16/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0858 - accuracy: 0.3201\n",
            "Epoch 17/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0854 - accuracy: 0.3249\n",
            "Epoch 18/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0850 - accuracy: 0.3300\n",
            "Epoch 19/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0846 - accuracy: 0.3358\n",
            "Epoch 20/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0843 - accuracy: 0.3393\n",
            "Epoch 21/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0839 - accuracy: 0.3458\n",
            "Epoch 22/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0835 - accuracy: 0.3512\n",
            "Epoch 23/150\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0830 - accuracy: 0.3555\n",
            "Epoch 24/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0826 - accuracy: 0.3623\n",
            "Epoch 25/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0822 - accuracy: 0.3675\n",
            "Epoch 26/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0818 - accuracy: 0.3742\n",
            "Epoch 27/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0813 - accuracy: 0.3808\n",
            "Epoch 28/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0809 - accuracy: 0.3874\n",
            "Epoch 29/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0804 - accuracy: 0.3939\n",
            "Epoch 30/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0799 - accuracy: 0.4011\n",
            "Epoch 31/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0795 - accuracy: 0.4077\n",
            "Epoch 32/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0790 - accuracy: 0.4141\n",
            "Epoch 33/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0785 - accuracy: 0.4216\n",
            "Epoch 34/150\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0780 - accuracy: 0.4291\n",
            "Epoch 35/150\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0776 - accuracy: 0.4354\n",
            "Epoch 36/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0771 - accuracy: 0.4444\n",
            "Epoch 37/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0766 - accuracy: 0.4502\n",
            "Epoch 38/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0761 - accuracy: 0.4563\n",
            "Epoch 39/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0756 - accuracy: 0.4642\n",
            "Epoch 40/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0751 - accuracy: 0.4700\n",
            "Epoch 41/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0746 - accuracy: 0.4764\n",
            "Epoch 42/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0741 - accuracy: 0.4821\n",
            "Epoch 43/150\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0736 - accuracy: 0.4884\n",
            "Epoch 44/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0731 - accuracy: 0.4937\n",
            "Epoch 45/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0726 - accuracy: 0.4987\n",
            "Epoch 46/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0721 - accuracy: 0.5039\n",
            "Epoch 47/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0716 - accuracy: 0.5087\n",
            "Epoch 48/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0711 - accuracy: 0.5138\n",
            "Epoch 49/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0706 - accuracy: 0.5185\n",
            "Epoch 50/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0701 - accuracy: 0.5236\n",
            "Epoch 51/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0696 - accuracy: 0.5282\n",
            "Epoch 52/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0691 - accuracy: 0.5331\n",
            "Epoch 53/150\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0686 - accuracy: 0.5384\n",
            "Epoch 54/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0681 - accuracy: 0.5437\n",
            "Epoch 55/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0677 - accuracy: 0.5491\n",
            "Epoch 56/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0672 - accuracy: 0.5548\n",
            "Epoch 57/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0667 - accuracy: 0.5602\n",
            "Epoch 58/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0662 - accuracy: 0.5663\n",
            "Epoch 59/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0657 - accuracy: 0.5731\n",
            "Epoch 60/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0652 - accuracy: 0.5777\n",
            "Epoch 61/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0647 - accuracy: 0.5831\n",
            "Epoch 62/150\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0643 - accuracy: 0.5890\n",
            "Epoch 63/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0638 - accuracy: 0.5951\n",
            "Epoch 64/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0633 - accuracy: 0.6006\n",
            "Epoch 65/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0628 - accuracy: 0.6061\n",
            "Epoch 66/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0624 - accuracy: 0.6116\n",
            "Epoch 67/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0619 - accuracy: 0.6172\n",
            "Epoch 68/150\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0614 - accuracy: 0.6217\n",
            "Epoch 69/150\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0610 - accuracy: 0.6273\n",
            "Epoch 70/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0605 - accuracy: 0.6327\n",
            "Epoch 71/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0601 - accuracy: 0.6378\n",
            "Epoch 72/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0596 - accuracy: 0.6429\n",
            "Epoch 73/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0592 - accuracy: 0.6478\n",
            "Epoch 74/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0587 - accuracy: 0.6529\n",
            "Epoch 75/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0583 - accuracy: 0.6569\n",
            "Epoch 76/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0578 - accuracy: 0.6617\n",
            "Epoch 77/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0574 - accuracy: 0.6653\n",
            "Epoch 78/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0570 - accuracy: 0.6694\n",
            "Epoch 79/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0565 - accuracy: 0.6732\n",
            "Epoch 80/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0561 - accuracy: 0.6771\n",
            "Epoch 81/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0557 - accuracy: 0.6807\n",
            "Epoch 82/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0553 - accuracy: 0.6852\n",
            "Epoch 83/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0549 - accuracy: 0.6887\n",
            "Epoch 84/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0545 - accuracy: 0.6917\n",
            "Epoch 85/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0541 - accuracy: 0.6941\n",
            "Epoch 86/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0537 - accuracy: 0.6979\n",
            "Epoch 87/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0533 - accuracy: 0.7006\n",
            "Epoch 88/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0529 - accuracy: 0.7033\n",
            "Epoch 89/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0525 - accuracy: 0.7061\n",
            "Epoch 90/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0521 - accuracy: 0.7088\n",
            "Epoch 91/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0517 - accuracy: 0.7113\n",
            "Epoch 92/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0514 - accuracy: 0.7141\n",
            "Epoch 93/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0510 - accuracy: 0.7172\n",
            "Epoch 94/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0506 - accuracy: 0.7199\n",
            "Epoch 95/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0502 - accuracy: 0.7224\n",
            "Epoch 96/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0499 - accuracy: 0.7254\n",
            "Epoch 97/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0495 - accuracy: 0.7277\n",
            "Epoch 98/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0492 - accuracy: 0.7301\n",
            "Epoch 99/150\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0488 - accuracy: 0.7324\n",
            "Epoch 100/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0485 - accuracy: 0.7343\n",
            "Epoch 101/150\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0481 - accuracy: 0.7367\n",
            "Epoch 102/150\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0478 - accuracy: 0.7389\n",
            "Epoch 103/150\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0475 - accuracy: 0.7407\n",
            "Epoch 104/150\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0471 - accuracy: 0.7430\n",
            "Epoch 105/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0468 - accuracy: 0.7448\n",
            "Epoch 106/150\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0465 - accuracy: 0.7467\n",
            "Epoch 107/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0462 - accuracy: 0.7490\n",
            "Epoch 108/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0459 - accuracy: 0.7510\n",
            "Epoch 109/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0455 - accuracy: 0.7530\n",
            "Epoch 110/150\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0452 - accuracy: 0.7553\n",
            "Epoch 111/150\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0449 - accuracy: 0.7569\n",
            "Epoch 112/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0446 - accuracy: 0.7591\n",
            "Epoch 113/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0443 - accuracy: 0.7610\n",
            "Epoch 114/150\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0440 - accuracy: 0.7628\n",
            "Epoch 115/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0437 - accuracy: 0.7651\n",
            "Epoch 116/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0434 - accuracy: 0.7670\n",
            "Epoch 117/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0432 - accuracy: 0.7690\n",
            "Epoch 118/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0429 - accuracy: 0.7714\n",
            "Epoch 119/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0426 - accuracy: 0.7732\n",
            "Epoch 120/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0423 - accuracy: 0.7751\n",
            "Epoch 121/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0420 - accuracy: 0.7772\n",
            "Epoch 122/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0418 - accuracy: 0.7792\n",
            "Epoch 123/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0415 - accuracy: 0.7815\n",
            "Epoch 124/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0412 - accuracy: 0.7834\n",
            "Epoch 125/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0410 - accuracy: 0.7856\n",
            "Epoch 126/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0407 - accuracy: 0.7878\n",
            "Epoch 127/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0405 - accuracy: 0.7898\n",
            "Epoch 128/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0402 - accuracy: 0.7915\n",
            "Epoch 129/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0400 - accuracy: 0.7933\n",
            "Epoch 130/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0397 - accuracy: 0.7952\n",
            "Epoch 131/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0395 - accuracy: 0.7971\n",
            "Epoch 132/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0392 - accuracy: 0.7990\n",
            "Epoch 133/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0390 - accuracy: 0.8010\n",
            "Epoch 134/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0387 - accuracy: 0.8022\n",
            "Epoch 135/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0385 - accuracy: 0.8041\n",
            "Epoch 136/150\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0383 - accuracy: 0.8057\n",
            "Epoch 137/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0380 - accuracy: 0.8070\n",
            "Epoch 138/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0378 - accuracy: 0.8091\n",
            "Epoch 139/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0376 - accuracy: 0.8108\n",
            "Epoch 140/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0374 - accuracy: 0.8127\n",
            "Epoch 141/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0372 - accuracy: 0.8141\n",
            "Epoch 142/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0369 - accuracy: 0.8156\n",
            "Epoch 143/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0367 - accuracy: 0.8171\n",
            "Epoch 144/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0365 - accuracy: 0.8189\n",
            "Epoch 145/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0363 - accuracy: 0.8201\n",
            "Epoch 146/150\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0361 - accuracy: 0.8216\n",
            "Epoch 147/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0359 - accuracy: 0.8227\n",
            "Epoch 148/150\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0357 - accuracy: 0.8244\n",
            "Epoch 149/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0355 - accuracy: 0.8253\n",
            "Epoch 150/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0353 - accuracy: 0.8267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, Y = fetch_openml(data_id=1464, return_X_y=True)\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, stratify=Y)\n",
        "\n",
        "clf = make_pipeline(StandardScaler(), LogisticRegression(random_state=0))\n",
        "clf.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiPE1lpuHw43",
        "outputId": "1db64cb3-0138-4e54-abb0-bc501b709dd5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('logisticregression', LogisticRegression(random_state=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "Y_pred = clf.predict(X_valid)\n",
        "cm = confusion_matrix(Y_valid, Y_pred)\n",
        "\n",
        "cm_display = ConfusionMatrixDisplay(cm).plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "-qiAXlw3MBdC",
        "outputId": "683772b0-c422-432e-d572-33a20a6b6c34"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}